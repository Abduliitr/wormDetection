{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Frames\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"../video/test.mov\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from ..convenience import is_cv3\n",
    "import cv2\n",
    "\n",
    "def count_frames(path, override=False):\n",
    "\t# grab a pointer to the video file and initialize the total\n",
    "\t# number of frames read\n",
    "\tvideo = cv2.VideoCapture(path)\n",
    "\ttotal = 0\n",
    "\n",
    "\t# if the override flag is passed in, revert to the manual\n",
    "\t# method of counting frames\n",
    "\tif override:\n",
    "\t\ttotal = count_frames_manual(video)\n",
    "\n",
    "\t# otherwise, let's try the fast way first\n",
    "\telse:\n",
    "\t\t# lets try to determine the number of frames in a video\n",
    "\t\t# via video properties; this method can be very buggy\n",
    "\t\t# and might throw an error based on your OpenCV version\n",
    "\t\t# or may fail entirely based on your which video codecs\n",
    "\t\t# you have installed\n",
    "\t\ttry:\n",
    "\t\t\t# check if we are using OpenCV 3\n",
    "\t\t\tif is_cv3():\n",
    "\t\t\t\ttotal = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\t\t\t# otherwise, we are using OpenCV 2.4\n",
    "\t\t\telse:\n",
    "\t\t\t\ttotal = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\t\t# uh-oh, we got an error -- revert to counting manually\n",
    "\t\texcept:\n",
    "\t\t\ttotal = count_frames_manual(video)\n",
    "\n",
    "\t# release the video file pointer\n",
    "\tvideo.release()\n",
    "\n",
    "\t# return the total number of frames in the video\n",
    "\treturn total\n",
    "\n",
    "def count_frames_manual(video):\n",
    "\t# initialize the total number of frames read\n",
    "\ttotal = 0\n",
    "\n",
    "\t# loop over the frames of the video\n",
    "\twhile True:\n",
    "\t\t# grab the current frame\n",
    "\t\t(grabbed, frame) = video.read()\n",
    "\t \n",
    "\t\t# check to see if we have reached the end of the\n",
    "\t\t# video\n",
    "\t\tif not grabbed:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# increment the total number of frames read\n",
    "\t\ttotal += 1\n",
    "\n",
    "\t# return the total number of frames in the video file\n",
    "\treturn total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read_display_Video_frames\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('temp.mp4')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame',frame)\n",
    " \n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): ##Wait time is in milliseconds\n",
    "      break\n",
    " \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read video details\n",
    "import cv2\n",
    "\n",
    "fn = 'test.mp4'\n",
    "cap = cv2.VideoCapture(fn)\n",
    "\n",
    "# # if not cap.isOpened(): \n",
    "# #     print \"could not open :\",fn\n",
    "# #     return\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "duration = float(total_frames/fps)\n",
    "\n",
    "print(total_frames)\n",
    "print(width)\n",
    "print(height)\n",
    "print(fps)\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simple image thresholding\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../../mobile/image1.jpeg',0)\n",
    "# img = cv2.imread('../../mobile/image2.jpg',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "cv2.imshow('Original',img)\n",
    "# cv2.imshow('Thresh1',thresh1)\n",
    "# cv2.imshow('Thresh2',thresh2)\n",
    "# cv2.imshow('Thresh3',thresh3)\n",
    "# cv2.imshow('Thresh4',thresh4)\n",
    "# cv2.imshow('Thresh5',thresh5)\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "#     plt.title(titles[i])\n",
    "#     plt.xticks([]),plt.yticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read image using OpenCV \n",
    "\n",
    "# importing OpenCV(cv2) module \n",
    "import cv2 \n",
    "\n",
    "# Save image in set directory \n",
    "# Read RGB image \n",
    "img = cv2.imread('2.jpg') \n",
    "\n",
    "# Output img with window name as 'image' \n",
    "cv2.imshow('image', img) \n",
    "\n",
    "# Maintain output window utill \n",
    "# user presses a key \n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroying present windows on screen \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n",
    "# Python program to read  \n",
    "# image using matplotlib \n",
    "  \n",
    "# importing matplotlib modules \n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "# Read Images \n",
    "img = mpimg.imread('g4g.png') \n",
    "  \n",
    "# Output Images \n",
    "plt.imshow(img) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adaptive Thresholding\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('../../mobile/image1.jpeg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)','Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check dpi of an image\n",
    "from PIL import Image\n",
    "im = Image.open('../test_images/mobile/image1.jpeg')\n",
    "print(im.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the resoltion of an image\n",
    "\n",
    "def jpeg_res(filename):\n",
    "   \"\"\"\"This function prints the resolution of the jpeg image file passed into it\"\"\"\n",
    "\n",
    "   # open image for reading in binary mode\n",
    "   with open(filename,'rb') as img_file:\n",
    "\n",
    "       # height of image (in 2 bytes) is at 164th position\n",
    "       img_file.seek(163)\n",
    "\n",
    "       # read the 2 bytes\n",
    "       a = img_file.read(2)\n",
    "\n",
    "       # calculate height\n",
    "       height = (a[0] << 8) + a[1]\n",
    "\n",
    "       # next 2 bytes is width\n",
    "       a = img_file.read(2)\n",
    "\n",
    "       # calculate width\n",
    "       width = (a[0] << 8) + a[1]\n",
    "\n",
    "   print(\"The resolution of the image is\",width,\"x\",height)\n",
    "\n",
    "jpeg_res(\"../test_images/mobile/image1.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Detect_count2.py\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "# import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "  \n",
    "# # construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "#     help=\"path to the input image\")\n",
    "# ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "#     help=\"path to the output image\")\n",
    "# args = vars(ap.parse_args())\n",
    "  \n",
    "# load the image\n",
    "# image_orig = cv2.imread(args[\"image\"])\n",
    "\n",
    "image_orig = cv2.imread(\"./../test_images/BINARY.png\")\n",
    "\n",
    "# dict to count colonies\n",
    "counter = {}\n",
    "\n",
    "#print (image_orig)\n",
    "height_orig, width_orig = image_orig.shape[:2]\n",
    " \n",
    "# output image with contours\n",
    "image_contours = image_orig.copy()\n",
    " \n",
    "# DETECTING WHITE COLONIES\n",
    "colors = {\n",
    "    'white': ((150, 150, 150), (255, 255, 255))\n",
    "    # 'blue': ((255, 0, 0), (255, 125, 125)),\n",
    "    # 'yellow' ....\n",
    "}\n",
    "# colors = ['white']\n",
    "for color in colors:\n",
    " \n",
    "    # copy of original image\n",
    "    image_to_process = image_orig.copy()\n",
    " \n",
    "    # initializes counter\n",
    "    counter[color] = 0\n",
    " \n",
    "    # define NumPy arrays of color boundaries (GBR vectors)\n",
    "    if color == 'white':\n",
    "        # invert image colors\n",
    "        image_to_process = (255-image_to_process)\n",
    "        lower = np.array([ 50,  50,  40])\n",
    "        upper = np.array([255, 255,  255])\n",
    " \n",
    "    # find the colors within the specified boundaries\n",
    "    image_mask = cv2.inRange(image_to_process, lower, upper)\n",
    "    # apply the mask\n",
    "    image_res = cv2.bitwise_and(image_to_process, image_to_process, mask = image_mask)\n",
    " \n",
    "    ## load the image, convert it to grayscale, and blur it slightly\n",
    "    image_gray = cv2.cvtColor(image_res, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray = cv2.GaussianBlur(image_gray, (5, 5), 0)\n",
    " \n",
    "    # perform edge detection, then perform a dilation + erosion to close gaps in between object edges\n",
    "    image_edged = cv2.Canny(image_gray, 50, 100)\n",
    "    image_edged = cv2.dilate(image_edged, None, iterations=1)\n",
    "    image_edged = cv2.erode(image_edged, None, iterations=1)\n",
    " \n",
    "    # find contours in the edge map\n",
    "    cnts, cnts1 = cv2.findContours(image_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    " \n",
    "    # loop over the contours individually\n",
    "    for c in cnts:\n",
    "         \n",
    "        # if the contour is not sufficiently large, ignore it\n",
    "        if ((cv2.contourArea(c) < 5) or (cv2.contourArea(c) > 137)) :\n",
    "            continue\n",
    "        #  ontourArea(contours[i]);\n",
    "        # compute the Convex Hull of the contour\n",
    "        hull = cv2.convexHull(c)\n",
    "        if color == 'white':\n",
    "            # prints contours in green color\n",
    "            cv2.drawContours(image_contours,[hull],0,(0,255,0),1)\n",
    " \n",
    "        counter[color] += 1\n",
    "        #cv2.putText(image_contours, \"{:.0f}\".format(cv2.contourArea(c)), (int(hull[0][0][0]), int(hull[0][0][1])), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 255, 255), 2)\n",
    " \n",
    "    # Print the number of colonies of each color\n",
    "    print(\"{} {} colonies\".format(counter[color],color))\n",
    " \n",
    "# # Writes the output image\n",
    "# cv2.imwrite(args[\"output\"],image_contours)\n",
    "\n",
    "cv2.imwrite(\"./../output/1.png\",image_contours)\n",
    "\n",
    "# Also shows the result image\n",
    "cv2.imshow('Result_image',image_contours)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Python program to use contours to count the objects in an image.\n",
    " *\n",
    " * usage: python Contours.py <filename> <threshold>\n",
    "'''\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# read command-line arguments\n",
    "filename = \"./../test_images/BINARY.png\"\n",
    "t = 50\n",
    "\n",
    "# read original image\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# create binary image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "(t, binary) = cv2.threshold(blur, t, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# find contours\n",
    "(contours, _) = cv2.findContours(binary, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# print table of contours and sizes\n",
    "print(\"Found %d objects.\" % len(contours))\n",
    "for (i, c) in enumerate(contours):\n",
    "    print(\"\\tSize of contour %d: %d\" % (i, len(c)))\n",
    "\n",
    "# draw contours over original image\n",
    "cv2.drawContours(img, contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "# display original image with contours\n",
    "cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/imgproc/src/drawing.cpp:2498: error: (-215:Assertion failed) 0 <= contourIdx && contourIdx < (int)last in function 'drawContours'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3fa94a27911c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m###The following method is more useful in complex conditions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## Third is contour color and 4th argument is contour thickness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/drawing.cpp:2498: error: (-215:Assertion failed) 0 <= contourIdx && contourIdx < (int)last in function 'drawContours'\n"
     ]
    }
   ],
   "source": [
    "## Not working\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im2 = cv2.imread('./../test_images/BINARY.png')\n",
    "imgray = cv2.cvtColor(im2,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "\n",
    "\n",
    "#### Find contours of a binary image\n",
    "###first one is source image, \n",
    "###second is contour retrieval mode, \n",
    "###third is contour approximation method. \n",
    "###It outputs the contours and hierarchy. \n",
    "###Contours is a Python list of all the contours in the image. Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object.\n",
    "im2, contours = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# im2, contours = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE) ## Stores all the boundary points in a contour\n",
    "#cv2.RETR_EXTERNAL ## Second Argument To detect only boundaries\n",
    "\n",
    "contours = np.array(contours).reshape((-1,1,2)).astype(np.int32)\n",
    "#### To draw all the contours in an image:\n",
    "### ts first argument is source image, \n",
    "###second argument is the contours which should be passed as a Python list,\n",
    "###third argument is index of contours (useful when drawing individual contour. To draw all contours, pass -1) and\n",
    "###remaining arguments are color, thickness etc.\n",
    "# cv2.drawContours(thresh, contours, -1, (0,255,0), 3)\n",
    "###The following method is more useful in complex conditions\n",
    "cnt = contours[4]\n",
    "cv2.drawContours(thresh, cnt, 4, (0,0,255), 1) ## Third is contour color and 4th argument is contour thickness\n",
    "\n",
    "### \n",
    "cv2.imshow('output2', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of contours and size of each contour\n",
    "print(\"Found %d objects.\" % len(contours))\n",
    "for (i, c) in enumerate(contours):\n",
    "    print(\"\\tSize of contour %d: %d\" % (i, len(c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OPEN CV 4.0.0  ### https://docs.opencv.org/4.0.0/da/d22/tutorial_py_canny.html\n",
    "### https://mmeysenburg.github.io/image-processing/09-contours/\n",
    "### https://mmeysenburg.github.io/image-processing/07-thresholding/\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "im = cv.imread('./../test_images/BINARY.png')\n",
    "imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv.drawContours(im, contours, -1, (0,255,0), 3)\n",
    "\n",
    "# cv.drawContours(img, contours, 3, (0,255,0), 3)\n",
    "# cnt = contours[4]\n",
    "# cv.drawContours(img, [cnt], 0, (0,255,0), 3)\n",
    "cv2.imshow('output2', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##OPEN CV 4.0.0\n",
    "### CANNY EDGE DETECTION\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./../test_images/BINARY.png')\n",
    "edges = cv.Canny(img,100,200)\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# cv.imshow('output2', edges)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
